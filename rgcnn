# Import required libraries
import shutil
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from PIL import Image
import os
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
from keras.layers import Layer
from keras.activations import relu
from keras.callbacks import EarlyStopping
from tensorflow.keras import backend as K


# Load the dataset
data = []
labels = []
classes = 43
cur_path = os.getcwd()

for i in range(classes):
    path = os.path.join('/content/Train', str(i))
    images = os.listdir(path)
    for a in images:
        try:
            image = Image.open(os.path.join(path, a))
            image = image.resize((30, 30))
            image = np.array(image)
            data.append(image)
            labels.append(i)
        except:
            print("Error loading image")

data = np.array(data)
labels = np.array(labels)

# Splitting training and testing dataset
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

# Converting the labels into one-hot encoding
y_train = to_categorical(y_train, 43)
y_test = to_categorical(y_test, 43)

X_train = X_train / 255.0
X_test = X_test / 255.0

class RecursiveGatedConv(Layer):
    def __init__(self, filters, kernel_size, activation, num_steps, **kwargs):
        super(RecursiveGatedConv, self).__init__(**kwargs)
        self.filters = filters
        self.kernel_size = kernel_size
        self.activation = activation
        self.num_steps = num_steps
        self.conv = Conv2D(filters, kernel_size, padding='same', activation=activation)
        self.gate = Conv2D(filters, kernel_size, padding='same', activation='sigmoid')

    def call(self, inputs):
        x = inputs
        for i in range(self.num_steps):
            h = self.conv(x)
            g = self.gate(x)
            x = self.activation(h * g + x)
        return x

    def get_config(self):
        config = super().get_config()
        config.update({
            'filters': self.filters,
            'kernel_size': self.kernel_size,
            'activation': self.activation,
            'num_steps': self.num_steps
        })
        return config

# Build the RGCN model
model_rgcnn = Sequential()
model_rgcnn.add(Conv2D(filters=3, kernel_size=(1, 1), padding='same', input_shape=X_train.shape[1:]))
model_rgcnn.add(RecursiveGatedConv(filters=3, kernel_size=(5, 5), activation=relu, num_steps=2))
model_rgcnn.add(RecursiveGatedConv(filters=3, kernel_size=(5, 5), activation=relu, num_steps=2))
model_rgcnn.add(MaxPool2D(pool_size=(2, 2)))
model_rgcnn.add(Dropout(rate=0.25))
model_rgcnn.add(Conv2D(filters=32, kernel_size=(1, 1), padding='same'))
model_rgcnn.add(RecursiveGatedConv(filters=32, kernel_size=(3, 3), activation=relu, num_steps=2))
model_rgcnn.add(RecursiveGatedConv(filters=32, kernel_size=(3, 3), activation=relu, num_steps=2))
model_rgcnn.add(MaxPool2D(pool_size=(2, 2)))
model_rgcnn.add(Dropout(rate=0.25))
model_rgcnn.add(Flatten())
model_rgcnn.add(Dense(256, activation='relu'))
model_rgcnn.add(Dropout(rate=0.5))
model_rgcnn.add(Dense(43, activation='softmax'))

import os
# Import EarlyStopping callback
from keras.callbacks import EarlyStopping, ModelCheckpoint
# Create a folder named "checkpoints" if it doesn't exist
checkpoints_folder = "/content/drive/MyDrive/checkpoints"
if not os.path.exists(checkpoints_folder):
    os.makedirs(checkpoints_folder)
checkpoint_rgcnn_path = os.path.join(checkpoints_folder, "model_rgcnn_2.h5")

# Define model callbacks for saving checkpoints
checkpoint_rgcnn = ModelCheckpoint(checkpoint_rgcnn_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

# Compile the model
model_rgcnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model_rgcnn.summary()

# Import EarlyStopping callback
from keras.callbacks import EarlyStopping

# Define early stopping criteria
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)

# Fit the model with early stopping
history_rgcnn= model_rgcnn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, callbacks=[checkpoint_rgcnn])
import matplotlib.pyplot as plt

# Get training history
training_loss = history_rgcnn.history['loss']
validation_loss = history_rgcnn.history['val_loss']
training_accuracy = history_rgcnn.history['accuracy']
validation_accuracy = history_rgcnn.history['val_accuracy']
epochs = range(1, len(training_loss) + 1)

# Plot model loss over time
plt.figure(figsize=(10, 8))
plt.plot(epochs, training_loss, 'b', label='Training Loss')
plt.plot(epochs, validation_loss, 'r', label='Validation Loss')
plt.title('RGCNN Model Loss Over Time (GTSRB)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# Plot model accuracy over time
plt.figure(figsize=(10, 8))
plt.plot(epochs, training_accuracy, 'b', label='Training Accuracy')
plt.plot(epochs, validation_accuracy, 'r', label='Validation Accuracy')
plt.title('RGCNN Model Accuracy Over Time (GTSRB)')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Predict labels for the test set
y_pred = model_rgcnn.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true_classes = np.argmax(y_test, axis=1)

# Compute confusion matrix
conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('RGCNN Confusion Matrix (GTSRB)')
plt.show()

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer
import matplotlib.pyplot as plt

# Binarize the output
lb = LabelBinarizer()
lb.fit(y_true_classes)
y_test_bin = lb.transform(y_true_classes)
y_pred_bin = lb.transform(y_pred_classes)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(43):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_bin[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test_bin.ravel(), y_pred_bin.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])

# Compute macro-average ROC curve and ROC area
all_fpr = np.unique(np.concatenate([fpr[i] for i in range(43)]))
mean_tpr = np.zeros_like(all_fpr)
for i in range(43):
    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])
mean_tpr /= 43
fpr["macro"] = all_fpr
tpr["macro"] = mean_tpr
roc_auc["macro"] = auc(fpr["macro"], tpr["macro"])


# Plot all ROC curves
plt.figure(figsize=(10, 8))
plt.plot(fpr["micro"], tpr["micro"],
         label='micro-average ROC curve (area = {0:0.2f})'
               ''.format(roc_auc["micro"]),
         color='purple', linestyle=':', linewidth=4)

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('RGCN Receiver Operating Characteristic (GTSRB)')
plt.legend(loc="lower right")
plt.show()
